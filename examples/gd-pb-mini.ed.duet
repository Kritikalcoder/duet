-- gradient descent
-- per-iteration bound
-- with minibatching
let main = pλ m  : ℕ,
              n  : ℕ,
              ε  : ℝ⁺,
              k  : ℕ,
              δ  : ℝ⁺,
              δ′ : ℝ⁺,
              b  : ℕ
              .
              xs : 𝕄 [L∞, U|m, n⋅𝔻 ] ,
              ys : 𝕄 [L∞, U|m, 1⋅𝔻 ] ,
              ε  : ℝ⁺[ε],
              k  : ℕ[k],
              δ  : ℝ⁺[δ],
              δ′ : ℝ⁺[δ′],
              η  : ℝ,
              b  : ℕ[b]
              ⇒
  let m₀ = mcreate[ L∞ | ℕ[1] , cols xs ] { i , j ⇒ 0.0 } in
  -- let b = ℕ[50] in
  let c = box (mclip[L2] xs) in
  aloop[ δ′ ] k on m₀ <xs,ys> { t , θ ⇒
    g ← sample[ b ] (unbox c), ys {xs', ys' ⇒
        let s = ℝ⁺[1.0] / real (rows xs') in
        mgauss[ s , ε , δ ] <xs',ys'> { ∇[ LR | θ ; xs' , ys' ] } };
    return mmap θ , mmap g { x ⇒ η ⋅ x } { x , y ⇒ x - y }
  }
in return main
