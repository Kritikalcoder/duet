-- gradient descent
-- per-iteration bound
-- with minibatching
let main = pλ m  : ℕ,
              n  : ℕ,
              ε  : ℝ⁺,
              α  : ℕ,
              k  : ℕ,
              b  : ℕ
              .
              xs : 𝕄 [L∞, U|m, n⋅𝔻 ] ,
              ys : 𝕄 [L∞, U|m, 1⋅𝔻 ] ,
              α  : ℕ[α],
              ε  : ℝ⁺[ε],
              k  : ℕ[k],
              η  : ℝ,
              b  : ℕ[b]
              ⇒
  let m₀ = mcreate[ L∞ | ℕ[1] , cols xs ] { i , j ⇒ 0.0 } in
  loop k on m₀ <xs,ys> { t , θ ⇒
    g ← sample[ b ] xs, ys {xs', ys' ⇒
        let s = ℝ⁺[1.0] / real (rows xs') in
        mgauss[ s , α, ε ] <xs',ys'> { ∇[ LR | θ ; mclip[L2] xs' , ys' ] } };
    return mmap θ , mmap g { x ⇒ η ⋅ x } { x , y ⇒ x - y }
  }
in return main
